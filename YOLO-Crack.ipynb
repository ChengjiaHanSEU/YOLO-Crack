{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fe5b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4284\\2475163635.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, MaxPool2D\n",
    "from tensorflow import keras\n",
    "\n",
    "from absl.flags import FLAGS\n",
    "from absl import app, flags\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import yaml\n",
    "import math\n",
    "import numpy as np\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import pynvml \n",
    "from tensorflow.python.client import device_lib\n",
    "import math\n",
    "import pandas as pd\n",
    "device_lib.list_local_devices()\n",
    "import shutil\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "import colorsys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b754185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(keras.layers.Layer):\n",
    "    def __init__(self, c1, c2, k, s=1, g=1, bias=True, w=None):\n",
    "        super(Conv2d, self).__init__()\n",
    "        assert g == 1, \"TF v2.2 Conv2D does not support 'groups' argument\"\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            c2, k, s, 'VALID', use_bias=bias,\n",
    "            kernel_initializer=keras.initializers.Constant(w.weight.permute(2, 3, 1, 0).numpy()),\n",
    "            bias_initializer=keras.initializers.Constant(w.bias.numpy()) if bias else None, )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.conv(inputs)\n",
    "\n",
    "\n",
    "class LeakyRelu(object):\n",
    "    def __call__(self, x):\n",
    "        return tf.nn.leaky_relu(x)\n",
    "\n",
    "class Conv(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding='SAME', groups=1):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = Conv2D(filters, kernel_size, strides, padding, groups=groups, use_bias=False,\n",
    "                           kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                           kernel_regularizer=tf.keras.regularizers.L2(5e-4))\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyRelu()\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.activation(self.bn(self.conv(x)))\n",
    "\n",
    "class Focus(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, padding='SAME'):\n",
    "        super(Focus, self).__init__()\n",
    "        self.conv = Conv(filters, kernel_size, strides, padding)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.conv(tf.concat([x[..., ::2, ::2, :],\n",
    "                                    x[..., 1::2, ::2, :],\n",
    "                                    x[..., ::2, 1::2, :],\n",
    "                                    x[..., 1::2, 1::2, :]],\n",
    "                                   axis=-1))\n",
    "\n",
    "    \n",
    "class Bottleneck(Layer):\n",
    "    def __init__(self, units, shortcut=True, expansion=0.5):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = Conv(int(units * expansion), 1, 1)\n",
    "        self.conv2 = Conv(units, 3, 1)\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.shortcut:\n",
    "            return x + self.conv2(self.conv1(x))\n",
    "        return self.conv2(self.conv1(x))\n",
    "\n",
    "\n",
    "class BottleneckCSP(Layer):\n",
    "    def __init__(self, units, n_layer=1, shortcut=True, expansion=0.5):\n",
    "        super(BottleneckCSP, self).__init__()\n",
    "        units_e = int(units * expansion)\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv4 = Conv(units, 1, 1)\n",
    "        self.bn = BatchNormalization(momentum=0.03)\n",
    "        self.activation = LeakyRelu()\n",
    "        self.modules = tf.keras.Sequential([Bottleneck(units_e, shortcut, expansion=1.0) for _ in range(n_layer)])\n",
    "\n",
    "    def call(self, x):\n",
    "        y1 = self.conv3(self.modules(self.conv1(x)))\n",
    "        y2 = self.conv2(x)\n",
    "        return self.conv4(self.activation(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class C3(Layer):\n",
    "    def __init__(self, units, n_layer=1, shortcut=False, expansion=0.5):\n",
    "        super(C3, self).__init__()\n",
    "        units_e = int(units)  # hidden channels\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv(units, 1, 1)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.activation = LeakyRelu()\n",
    "        self.modules = tf.keras.Sequential([Bottleneck(units_e, shortcut, expansion=1.0) for _ in range(n_layer)])\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        y1 = self.modules(x1)\n",
    "        y2 = self.conv2(x1)\n",
    "        return self.conv3(self.activation(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class SPP(Layer):\n",
    "    def __init__(self, units, kernels=(5, 9, 13)):\n",
    "        super(SPP, self).__init__()\n",
    "        units_e = units // 2  # Todo:\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv(units, 1, 1)\n",
    "        self.modules = [MaxPool2D(pool_size=x, strides=1, padding='SAME') for x in kernels]  # Todo: padding check\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(tf.concat([x] + [module(x) for module in self.modules], axis=-1))\n",
    "    \n",
    "class SPPF(Layer):\n",
    "    # Spatial pyramid pooling-Fast layer\n",
    "    def __init__(self, c1, c2, k=5, w=None):\n",
    "        super().__init__()\n",
    "        c_ = c1 // 2  # hidden channels\n",
    "        self.cv1 = Conv(c1, c_, 1, 1, w=w.cv1)\n",
    "        self.cv2 = Conv(c_ * 4, c2, 1, 1, w=w.cv2)\n",
    "        self.m = keras.layers.MaxPool2D(pool_size=k, strides=1, padding='SAME')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.cv1(inputs)\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "        return self.cv2(tf.concat([x, y1, y2, self.m(y2)], 3))\n",
    "\n",
    "class SPPCSP(Layer):\n",
    "    # Cross Stage Partial Networks\n",
    "    def __init__(self, units, n=1, shortcut=False, expansion=0.5, kernels=(5, 9, 13)):\n",
    "        super(SPPCSP, self).__init__()\n",
    "        units_e = int(2 * units * expansion)\n",
    "        self.conv1 = Conv(units_e, 1, 1)\n",
    "        self.conv2 = Conv2D(units_e, 1, 1, use_bias=False, kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        self.conv3 = Conv(units_e, 3, 1)\n",
    "        self.conv4 = Conv(units_e, 1, 1)\n",
    "        self.modules = [MaxPool2D(pool_size=x, strides=1, padding='same') for x in kernels]\n",
    "        self.conv5 = Conv(units_e, 1, 1)\n",
    "        self.conv6 = Conv(units_e, 3, 1)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.act = LeakyRelu()\n",
    "        self.conv7 = Conv(units, 1, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv4(self.conv3(self.conv1(x)))\n",
    "        y1 = self.conv6(self.conv5(tf.concat([x1] + [module(x1) for module in self.modules], axis=-1)))\n",
    "        y2 = self.conv2(x)\n",
    "        return self.conv7(self.act(self.bn(tf.concat([y1, y2], axis=-1))))\n",
    "\n",
    "\n",
    "class Upsample(Layer):\n",
    "    def __init__(self, i=None, ratio=2, method='bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.method = method\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.resize(x, (tf.shape(x)[1] * self.ratio, tf.shape(x)[2] * self.ratio), method=self.method)\n",
    "\n",
    "\n",
    "class Concat(Layer):\n",
    "    def __init__(self, dims=-1):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dims = dims\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.concat(x, self.dims)\n",
    "\n",
    "class Final_layer(keras.layers.Layer):\n",
    "    def __init__(self, nc=20, anchors=(), ch=(), imgsz=(640, 640), w=None):  # detection layer\n",
    "        super(Final_layer, self).__init__()\n",
    "        self.stride = np.array([8, 16, 32], np.float32)\n",
    "        self.nc = nc  # number of classes 20\n",
    "        self.no = nc + 5  # number of outputs per anchor(类别+x/y/w/h/Conf) 25\n",
    "        self.nl = len(anchors)  # number of detection layers 3\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors 3\n",
    "        self.grid = [tf.zeros(1)] * self.nl  # init grid \n",
    "        self.anchors = tf.cast(tf.reshape(anchors, [self.nl, -1, 2]), tf.float32) # (3,3,2)\n",
    "        self.m = [Conv2D(self.no * self.na, 1, use_bias=False) for _ in range(self.nl)]\n",
    "        self.training = False  # set to False after building model\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = []\n",
    "        for i in range(self.nl):\n",
    "            x.append(self.m[i](inputs[i]))\n",
    "            #print(self.m[i](inputs[i]).shape)\n",
    "            #x(bs,80, 80, 192) to x(None, 80, 80, 75)\n",
    "            #x(bs,40, 40, 384) to x(None, 40, 40, 75)\n",
    "            #x(bs,20,20,768)   to x(None, 20, 20, 75)\n",
    "        return x   \n",
    "\n",
    "class Detect(keras.layers.Layer):\n",
    "    def __init__(self, nc=20, anchors=(), ch=(), imgsz=(640, 640), w=None):  # detection layer\n",
    "        super(Detect, self).__init__()\n",
    "        self.stride = np.array([8, 16, 32], np.float32)\n",
    "        self.nc = nc  # number of classes 20\n",
    "        self.no = nc + 5  # number of outputs per anchor(类别+x/y/w/h/Conf) 25\n",
    "        self.nl = len(anchors)  # number of detection layers 3\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors 3\n",
    "        self.grid = [tf.zeros(1)] * self.nl  # init grid \n",
    "        self.anchors = tf.cast(tf.reshape(anchors, [self.nl, -1, 2]), tf.float32) # (3,3,2)\n",
    "        self.m = [Conv2D(self.no * self.na, 1, use_bias=False) for _ in range(self.nl)]\n",
    "        self.training = False  # set to False after building model\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z = []  # inference output\n",
    "        x = []\n",
    "        for i in range(self.nl):\n",
    "            x.append(self.m[i](inputs[i]))\n",
    "            #print(self.m[i](inputs[i]).shape)\n",
    "            #x(bs,80, 80, 192) to x(None, 80, 80, 75)\n",
    "            #x(bs,40, 40, 384) to x(None, 40, 40, 75)\n",
    "            #x(bs,20,20,768)   to x(None, 20, 20, 75)\n",
    "            ny, nx = self.imgsz[0] // self.stride[i], self.imgsz[1] // self.stride[i]\n",
    "            _, grid1, grid2, _ = self.m[i](inputs[i]).shape\n",
    "            #x[i] = tf.transpose(tf.reshape(x[i], [-1, ny * nx, self.na, self.no]), [0, 2, 1, 3])\n",
    "            x[i] = tf.reshape(self.m[i](inputs[i]), (-1, grid1, grid2, self.na, self.no))\n",
    "            #x(None, 80, 80, 75) to x(None, 80, 80, 3, 25)\n",
    "            #x(None, 40, 40, 75) to x(None, 40, 40, 3, 25)\n",
    "            #x(None, 20, 20, 75) to x(None, 20, 20, 3, 25)\n",
    "            if not self.training:  # inference\n",
    "                y = tf.sigmoid(x[i]) #输出结果约束在(0,1)\n",
    "                \n",
    "                grid_xy = tf.meshgrid(tf.range(grid1), tf.range(grid2))  # grid[x][y]==(y,x)\n",
    "                grid_xy = tf.cast(tf.expand_dims(tf.stack(grid_xy, axis=-1), axis=2),tf.float32)  \n",
    "                xy, wh, conf, classes = tf.split(y, (2, 2, 1, self.nc), axis=-1) #最后一个维度(25)把张量切分成2份，2份，1份，20份分别给4个变量\n",
    "                pred_xy = (xy * 2. - 0.5 + grid_xy) * self.stride[i]  # decode pred to xywh\n",
    "                pred_wh = (wh * 2) ** 2 * self.anchors[i] * self.stride[i]\n",
    "                #还原到原图大小的xywh\n",
    "                out = tf.concat([pred_xy, pred_wh, conf, classes], axis=-1)\n",
    "                #print(out.shape)\n",
    "                z.append(out)\n",
    "                #xy = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy\n",
    "                #wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]\n",
    "                # Normalize xywh to 0-1 to reduce calibration error\n",
    "                # xy /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)\n",
    "                # wh /= tf.constant([[self.imgsz[1], self.imgsz[0]]], dtype=tf.float32)\n",
    "                # y = tf.concat([xy, wh, y[..., 4:]], -1)\n",
    "                # z.append(tf.reshape(y, [-1, 3 * ny * nx, self.no]))        \n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_grid(nx=20, ny=20):\n",
    "        # yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])\n",
    "        # return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()\n",
    "        xv, yv = tf.meshgrid(tf.range(nx), tf.range(ny))\n",
    "        return tf.cast(tf.reshape(tf.stack([xv, yv], 2), [1, 1, ny * nx, 2]), dtype=tf.float32)\n",
    "    \n",
    "class AgnosticNMS(keras.layers.Layer):\n",
    "    # TF Agnostic NMS\n",
    "    def call(self, input, topk_all, iou_thres, conf_thres):\n",
    "        # wrap map_fn to avoid TypeSpec related error https://stackoverflow.com/a/65809989/3036450\n",
    "        return tf.map_fn(self._nms, input,\n",
    "                         fn_output_signature=(tf.float32, tf.float32, tf.float32, tf.int32),\n",
    "                         name='agnostic_nms')\n",
    "\n",
    "    @staticmethod\n",
    "    def _nms(x, topk_all=100, iou_thres=0.45, conf_thres=0.25):  # agnostic NMS\n",
    "        boxes, classes, scores = x\n",
    "        class_inds = tf.cast(tf.argmax(classes, axis=-1), tf.float32)\n",
    "        scores_inp = tf.reduce_max(scores, -1)\n",
    "        selected_inds = tf.image.non_max_suppression(\n",
    "            boxes, scores_inp, max_output_size=topk_all, iou_threshold=iou_thres, score_threshold=conf_thres)\n",
    "        selected_boxes = tf.gather(boxes, selected_inds)\n",
    "        padded_boxes = tf.pad(selected_boxes,\n",
    "                              paddings=[[0, topk_all - tf.shape(selected_boxes)[0]], [0, 0]],\n",
    "                              mode=\"CONSTANT\", constant_values=0.0)\n",
    "        selected_scores = tf.gather(scores_inp, selected_inds)\n",
    "        padded_scores = tf.pad(selected_scores,\n",
    "                               paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],\n",
    "                               mode=\"CONSTANT\", constant_values=-1.0)\n",
    "        selected_classes = tf.gather(class_inds, selected_inds)\n",
    "        padded_classes = tf.pad(selected_classes,\n",
    "                                paddings=[[0, topk_all - tf.shape(selected_boxes)[0]]],\n",
    "                                mode=\"CONSTANT\", constant_values=-1.0)\n",
    "        valid_detections = tf.shape(selected_inds)[0]\n",
    "        return padded_boxes, padded_scores, padded_classes, valid_detections    \n",
    "\n",
    "############################解析YOLO-v5的配置文件\".yaml\"构建keras框架下的网络层结构#######################################   \n",
    "def parse_model(yaml_dict):  # model_dict, input_channels(3)\n",
    "        anchors, nc = yaml_dict['anchors'], yaml_dict['nc']\n",
    "        depth_multiple, width_multiple = yaml_dict['depth_multiple'], yaml_dict['width_multiple']\n",
    "        num_anchors = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors\n",
    "        output_dims = num_anchors * (nc + 5)\n",
    "        layers = []\n",
    "        # from, number, module, args\n",
    "        for i, (f, number, module, args) in enumerate(yaml_dict['backbone'] + yaml_dict['head']):\n",
    "            # all component is a Class, initialize here, call in self.forward\n",
    "            module = eval(module) if isinstance(module, str) else module\n",
    "            for j, arg in enumerate(args):\n",
    "                try:\n",
    "                    args[j] = eval(arg) if isinstance(arg, str) else arg  # eval strings, like Detect(nc, anchors)\n",
    "                except:\n",
    "                    pass\n",
    "            number = max(round(number * depth_multiple), 1) if number > 1 else number  # control the model scale\n",
    "            if module in [Conv2D, Conv, Bottleneck, SPP, Focus, BottleneckCSP, C3]:\n",
    "                c2 = args[0]\n",
    "                c2 = math.ceil(c2 * width_multiple / 8) * 8 if c2 != output_dims else c2\n",
    "                args = [c2, *args[1:]]\n",
    "                if module in [BottleneckCSP, C3, SPPCSP]:\n",
    "                    args.insert(1, number)\n",
    "                    number = 1\n",
    "            modules = tf.keras.Sequential(*[module(*args) for _ in range(number)]) if number > 1 else module(*args)    \n",
    "            modules.i, modules.f = i, f\n",
    "            layers.append(modules)  \n",
    "        return layers #tf.keras.Sequential(layers)\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, cfg='yolov5s.yaml', ch=3, nc=20, model=None, imgsz=(640, 640)):  # model, channels, classes\n",
    "        super(Model, self).__init__()\n",
    "        if isinstance(cfg, dict):\n",
    "            self.yaml = cfg  # model dict\n",
    "        else:  # is *.yaml\n",
    "            import yaml  # for torch hub\n",
    "            self.yaml_file = Path(cfg).name\n",
    "            with open(cfg) as f:\n",
    "                self.yaml = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
    "        self.imgsz =imgsz\n",
    "        # Define model\n",
    "        if nc and nc != self.yaml['nc']:\n",
    "            print('Overriding %s nc=%g with nc=%g' % (cfg, self.yaml['nc'], nc))\n",
    "            self.yaml['nc'] = nc  # override yaml value\n",
    "        self.model = parse_model(self.yaml)\n",
    "        if isinstance(model, Detect):\n",
    "            # transfer the anchors to grid coordinator, 3 * 3 * 2\n",
    "            model.anchors /= tf.reshape(module.stride, [-1, 1, 1])\n",
    "\n",
    "     def predict(self, inputs, tf_nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45,\n",
    "                conf_thres=0.25):\n",
    "\n",
    "        y = []  # outputs\n",
    "        x = inputs\n",
    "        for i, m in enumerate(self.model):\n",
    "        #for m in self.model.layers:\n",
    "            if m.f != -1:  # if not from previous layer\n",
    "                # x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "                if isinstance(m.f, int):\n",
    "                    x = y[m.f]\n",
    "                else:\n",
    "                    x = [x if j == -1 else y[j] for j in m.f]\n",
    "            x = m(x)  # run\n",
    "            y.append(x)\n",
    "\n",
    "        return x,y[9],y[6],y[4]\n",
    "\n",
    "    def built_TFmodel(self, img_size, name='yolov5'):\n",
    "        x = tf.keras.Input([img_size, img_size, 3])\n",
    "        \n",
    "        output, conv, route_2,route_1 = self.predict(x)\n",
    "        \n",
    "        conv1 = tf.keras.layers.Conv2D(1024, 2, padding='same',trainable=True)(conv)\n",
    "        conv1 = tf.nn.leaky_relu(conv1)\n",
    "        conv1 = tf.keras.layers.Conv2DTranspose(512, 2, strides=2, padding='same',trainable=True)(conv1)\n",
    "        conv1 = tf.nn.leaky_relu(conv1)\n",
    "        for i in range(4):\n",
    "            conv1 = tf.keras.layers.Conv2D(512, 2, padding='same',trainable=True)(conv1)\n",
    "            conv1 = tf.nn.leaky_relu(conv1)\n",
    "            conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "\n",
    "        conv2 = tf.concat([conv1, route_2], axis=-1)\n",
    "        conv2 = tf.keras.layers.Conv2D(512, 2, padding='same',trainable=True)(conv2)\n",
    "        conv2 = tf.nn.leaky_relu(conv2)\n",
    "        conv2 = tf.keras.layers.Conv2DTranspose(256, 2, strides=2, padding='same',trainable=True)(conv2)\n",
    "        conv2 = tf.nn.leaky_relu(conv2)\n",
    "        for i in range(8):\n",
    "            conv2 = tf.keras.layers.Conv2D(256, 2, padding='same',trainable=True)(conv2)\n",
    "            conv2 = tf.nn.leaky_relu(conv2)\n",
    "            conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "\n",
    "        conv3 = tf.concat([conv2, route_1], axis=-1)\n",
    "        conv3 = tf.keras.layers.Conv2D(256, 2, padding='same',trainable=True)(conv3)\n",
    "        conv3 = tf.nn.leaky_relu(conv3)\n",
    "        conv3 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, padding='same',trainable=True)(conv3)\n",
    "        conv3 = tf.nn.leaky_relu(conv3)\n",
    "        for i in range(8):\n",
    "            conv3 = tf.keras.layers.Conv2D(128, 2, padding='same',trainable=True)(conv3)\n",
    "            conv3 = tf.nn.leaky_relu(conv3)\n",
    "            conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "\n",
    "        for i in range(2):\n",
    "            conv3= tf.keras.layers.Conv2DTranspose(64, 2, strides=2, padding='same',trainable=True)(conv3)\n",
    "            conv3 = tf.nn.leaky_relu(conv3)\n",
    "            conv3 = tf.keras.layers.Conv2D(64, 2, padding='same',trainable=True)(conv3)\n",
    "            conv3 = tf.nn.leaky_relu(conv3)\n",
    "            conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "\n",
    "        conv4 = tf.keras.layers.Conv2D(32, 2, padding='same',trainable=True)(conv3) \n",
    "        conv4 = tf.keras.layers.Conv2D(32, 2, padding='same',trainable=True)(conv4)\n",
    "        conv4 = tf.nn.leaky_relu(conv4)\n",
    "        output_data_image = tf.keras.layers.Conv2D(2, 1, padding='same',activation= \"softmax\",trainable=True)(conv4)  \n",
    "        \n",
    "        return tf.keras.Model(inputs=x, outputs=[output_data_image,output], name=name)\n",
    "        \n",
    "     # @staticmethod\n",
    "    def _xywh2xyxy(xywh):\n",
    "        # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
    "        x, y, w, h = tf.split(xywh, num_or_size_splits=4, axis=-1)\n",
    "        return tf.concat([x - w / 2, y - h / 2, x + w / 2, y + h / 2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建网络#\n",
    "def run(imgsz=(640, 640),  # inference size h,w\n",
    "         batch_size=1,  # batch size\n",
    "         dynamic=False):\n",
    "\n",
    "    # TensorFlow model\n",
    "    #im = tf.zeros((batch_size, 640, 640, 3))  # BHWC image\n",
    "    tf_model = Model(cfg='F:\\HCJ_for_AI_training\\Yolov5-TF-main\\Yolov5-TF-main\\yolov5.yaml', imgsz=imgsz, nc=4)\n",
    "    anchors = tf_model.model[-1].anchors\n",
    "    anchors = anchors / np.array([8,16,32])[:, np.newaxis]\n",
    "    #y = tf_model.predict(im)  # inference\n",
    "    TFmodel = tf_model.built_TFmodel(imgsz[0])\n",
    "    return TFmodel,anchors\n",
    "\n",
    "def decode(conv_output1,conv_output2,conv_output3,ANCHORS,num_classes=4):\n",
    "    \"\"\"\n",
    "    return tensor of shape [batch_size, output_size, output_size, anchor_per_scale, 5 + num_classes]\n",
    "            contains (x, y, w, h, score, probability)\n",
    "    conv_output1,conv_output2,conv_output3 = 80 ,40, 20      \n",
    "   \"\"\"\n",
    "    conv_shape1       = tf.shape(conv_output1)\n",
    "    conv_shape2       = tf.shape(conv_output2)\n",
    "    conv_shape3       = tf.shape(conv_output3)\n",
    "    batch_size        = conv_shape1[0]\n",
    "    output_size1      = conv_shape1[1]\n",
    "    output_size2      = conv_shape2[1]\n",
    "    output_size3      = conv_shape3[1]\n",
    "\n",
    "    # 对 tensor 进行 reshape\n",
    "    conv_output1 = tf.reshape(conv_output1, (batch_size, output_size1, output_size1, 3, 5 + num_classes))\n",
    "    conv_output2 = tf.reshape(conv_output2, (batch_size, output_size2, output_size2, 3, 5 + num_classes))\n",
    "    conv_output3 = tf.reshape(conv_output3, (batch_size, output_size3, output_size3, 3, 5 + num_classes))\n",
    "\n",
    "    # 按顺序提取[x, y, w, h, c]\n",
    "    conv_raw_dxdy1 = conv_output1[:, :, :, :, 0:2] # 中心位置的偏移量\n",
    "    conv_raw_dwdh1 = conv_output1[:, :, :, :, 2:4] # 预测框长宽的偏移量\n",
    "    conv_raw_conf1 = conv_output1[:, :, :, :, 4:5] # 预测框的置信度\n",
    "    conv_raw_prob1 = conv_output1[:, :, :, :, 5: ] # 预测框的类别概率\n",
    "    \n",
    "    conv_raw_dxdy2 = conv_output2[:, :, :, :, 0:2] # 中心位置的偏移量\n",
    "    conv_raw_dwdh2 = conv_output2[:, :, :, :, 2:4] # 预测框长宽的偏移量\n",
    "    conv_raw_conf2 = conv_output2[:, :, :, :, 4:5] # 预测框的置信度\n",
    "    conv_raw_prob2 = conv_output2[:, :, :, :, 5: ] # 预测框的类别概率\n",
    "    \n",
    "    conv_raw_dxdy3 = conv_output3[:, :, :, :, 0:2] # 中心位置的偏移量\n",
    "    conv_raw_dwdh3 = conv_output3[:, :, :, :, 2:4] # 预测框长宽的偏移量\n",
    "    conv_raw_conf3 = conv_output3[:, :, :, :, 4:5] # 预测框的置信度\n",
    "    conv_raw_prob3 = conv_output3[:, :, :, :, 5: ] # 预测框的类别概率\n",
    "\n",
    "    # 好了，接下来是画网格。其中，output_size1,2,3 等于 80、40 或者 20\n",
    "    y1 = tf.tile(tf.range(output_size1, dtype=tf.int32)[:, tf.newaxis], [1, output_size1])\n",
    "    x1 = tf.tile(tf.range(output_size1, dtype=tf.int32)[tf.newaxis, :], [output_size1, 1])\n",
    "    xy_grid1 = tf.concat([x1[:, :, tf.newaxis], y1[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid1 = tf.tile(xy_grid1[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid1 = tf.cast(xy_grid1, tf.float32) # 计算网格左上角的位置，即cx cy的值\n",
    "    \n",
    "    y2 = tf.tile(tf.range(output_size2, dtype=tf.int32)[:, tf.newaxis], [1, output_size2])\n",
    "    x2 = tf.tile(tf.range(output_size2, dtype=tf.int32)[tf.newaxis, :], [output_size2, 1])\n",
    "    xy_grid2 = tf.concat([x2[:, :, tf.newaxis], y2[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid2 = tf.tile(xy_grid2[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid2 = tf.cast(xy_grid2, tf.float32) # 计算网格左上角的位置，即cx cy的值\n",
    "\n",
    "    y3 = tf.tile(tf.range(output_size3, dtype=tf.int32)[:, tf.newaxis], [1, output_size3])\n",
    "    x3 = tf.tile(tf.range(output_size3, dtype=tf.int32)[tf.newaxis, :], [output_size3, 1])\n",
    "    xy_grid3 = tf.concat([x3[:, :, tf.newaxis], y3[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid3 = tf.tile(xy_grid3[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid3 = tf.cast(xy_grid3, tf.float32) # 计算网格左上角的位置，即cx cy的值\n",
    "    \n",
    "    # 根据上图公式计算预测框的中心位置\n",
    "    pred_xy1 = (tf.sigmoid(conv_raw_dxdy1) + xy_grid1) * 8 # 计算预测框在原图尺寸上的x y\n",
    "    pred_wh1 = ((tf.sigmoid(conv_raw_dwdh1)*2) * ANCHORS[0]) * 8 # 计算预测框在原图尺寸上的w h\n",
    "    #pred_xy1 = (tf.sigmoid(conv_raw_dxdy1) + xy_grid1) * 8 # 计算预测框在原图尺寸上的x y\n",
    "    #pred_wh1 = (tf.exp(conv_raw_dwdh1) * ANCHORS[0]) * 8 # 计算预测框在原图尺寸上的w h\n",
    "    pred_xywh1 = tf.concat([pred_xy1, pred_wh1], axis=-1) # 拼接起来\n",
    "    pred_conf1 = tf.sigmoid(conv_raw_conf1)# 计算预测框里object的置信度\n",
    "    pred_prob1 = tf.sigmoid(conv_raw_prob1) # 计算预测框里object的类别概率\n",
    "\n",
    "    pred_xy2 = (tf.sigmoid(conv_raw_dxdy2) + xy_grid2) * 16 # 计算预测框在原图尺寸上的x y\n",
    "    pred_wh2 = ((tf.sigmoid(conv_raw_dwdh2)*2) * ANCHORS[1]) * 16     # 计算预测框在原图尺寸上的w h\n",
    "    #pred_xy2 = (tf.sigmoid(conv_raw_dxdy2) + xy_grid2) * 16 # 计算预测框在原图尺寸上的x y\n",
    "    #pred_wh2 = (tf.exp(conv_raw_dwdh2) * ANCHORS[1]) * 16 # 计算预测框在原图尺寸上的w h\n",
    "    pred_xywh2 = tf.concat([pred_xy2, pred_wh2], axis=-1) # 拼接起来\n",
    "    pred_conf2 = tf.sigmoid(conv_raw_conf2) # 计算预测框里object的置信度\n",
    "    pred_prob2 = tf.sigmoid(conv_raw_prob2) # 计算预测框里object的类别概率\n",
    "    \n",
    "    pred_xy3 = (tf.sigmoid(conv_raw_dxdy3 ) + xy_grid3) * 32 # 计算预测框在原图尺寸上的x y\n",
    "    pred_wh3 = ((tf.sigmoid(conv_raw_dwdh3)*2) * ANCHORS[2]) * 32    # 计算预测框在原图尺寸上的w h\n",
    "    #pred_xy3 = (tf.sigmoid(conv_raw_dxdy3) + xy_grid3) * 32 # 计算预测框在原图尺寸上的x y\n",
    "    #pred_wh3 = (tf.exp(conv_raw_dwdh3) * ANCHORS[2]) * 32 # 计算预测框在原图尺寸上的w h\n",
    "    pred_xywh3 = tf.concat([pred_xy3, pred_wh3], axis=-1) # 拼接起来\n",
    "    pred_conf3 = tf.sigmoid(conv_raw_conf3) # 计算预测框里object的置信度\n",
    "    pred_prob3 = tf.sigmoid(conv_raw_prob3)# 计算预测框里object的类别概率\n",
    "    \n",
    "    decode_output1=tf.concat([pred_xywh1, pred_conf1, pred_prob1], axis=-1)\n",
    "    decode_output2=tf.concat([pred_xywh2, pred_conf2, pred_prob2], axis=-1)\n",
    "    decode_output3=tf.concat([pred_xywh3, pred_conf3, pred_prob3], axis=-1)\n",
    "    \n",
    "    return decode_output1,decode_output2,decode_output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a65c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############损失函数###########################\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / (union_area+1e-4) #[0,1]\n",
    "\n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    \n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
    "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
    "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    iou = inter_area / (union_area+1e-4)\n",
    "    \n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "\n",
    "    giou = iou - 1.0 * (enclose_area - union_area+1e-4) / (enclose_area+1e-4) #范围（-1，1]\n",
    "    \n",
    "    return giou\n",
    "\n",
    "\n",
    "def compute_loss(output_data_image, outputbox1,outputbox2,outputbox3, bboxes1, bboxes2, bboxes3, image_label,\n",
    "                 batch_lbboxes, batch_mbboxes,batch_sbboxes,conv_raw1, conv_raw2, conv_raw3):\n",
    "    \"\"\"\n",
    "    output_data_image = [batch_size,640,640,2] \n",
    "    outputbox1 = [batch_size, P/8，P/8，3,（4 + connf + num_classes）] \n",
    "    outputbox2 = [batch_size, P/16，P/16，3,（4 + connf + num_classes）] \n",
    "    outputbox3 = [batch_size, P/32，P/32，3,（4 + connf + num_classes）] \n",
    "    bboxes1 = [batch_size, P/8，P/8，3,（4 + connf + num_classes）] \n",
    "    bboxes2 = [batch_size, P/16，P/16，3,（4 + connf + num_classes）] \n",
    "    bboxes3 = [batch_size, P/32，P/32，3,（4 + connf + num_classes）] \n",
    "    image_label=[batch_size,640,640,2] \n",
    "    \"\"\"\n",
    "    num_classes = 4\n",
    "    batch_size=outputbox1.shape[0]\n",
    "    \n",
    "    conv_raw1 = tf.reshape(conv_raw1, (batch_size, 80, 80, 3, 5 + 4))\n",
    "    conv_raw2 = tf.reshape(conv_raw2, (batch_size, 40, 40, 3, 5 + 4))\n",
    "    conv_raw3 = tf.reshape(conv_raw3, (batch_size, 20, 20, 3, 5 + 4))\n",
    "    \n",
    "    #损失1;分类值损失\n",
    "    real_P1 = bboxes1[:,:,:,:,5:]\n",
    "    real_P2 = bboxes2[:,:,:,:,5:]\n",
    "    real_P3 = bboxes3[:,:,:,:,5:]\n",
    "    pred_P1 = outputbox1[:,:,:,:,5:]\n",
    "    pred_P2 = outputbox2[:,:,:,:,5:]\n",
    "    pred_P3 = outputbox3[:,:,:,:,5:]\n",
    "    prob_loss1 =  tf.keras.losses.categorical_crossentropy(real_P1, pred_P1+1e-10)\n",
    "    prob_loss2 =  tf.keras.losses.categorical_crossentropy(real_P2, pred_P2+1e-10)\n",
    "    prob_loss3 =  tf.keras.losses.categorical_crossentropy(real_P3, pred_P3+1e-10)\n",
    "    Prob_loss1 = tf.reduce_mean(tf.reduce_sum(prob_loss1,axis=[1,2,3]))\n",
    "    Prob_loss2 = tf.reduce_mean(tf.reduce_sum(prob_loss2,axis=[1,2,3]))\n",
    "    Prob_loss3 = tf.reduce_mean(tf.reduce_sum(prob_loss3,axis=[1,2,3]))\n",
    "    Prob_loss = Prob_loss1 + Prob_loss2 + Prob_loss3\n",
    "    \n",
    "   #损失2;Iou损失\n",
    "    real_boxes1 = bboxes1[:,:,:,:,0:4]\n",
    "    real_boxes2 = bboxes2[:,:,:,:,0:4]\n",
    "    real_boxes3 = bboxes3[:,:,:,:,0:4]\n",
    "\n",
    "    pred_boxes1 = outputbox1[:,:,:,:,0:4]\n",
    "    pred_boxes2 = outputbox2[:,:,:,:,0:4]\n",
    "    pred_boxes3 = outputbox3[:,:,:,:,0:4]\n",
    "    \n",
    "    input_size = tf.cast(640, tf.float32)\n",
    "    \n",
    "    giou1 = tf.expand_dims(bbox_giou( pred_boxes1, real_boxes1), axis=-1)\n",
    "    giou2 = tf.expand_dims(bbox_giou( pred_boxes2, real_boxes2), axis=-1)\n",
    "    giou3 = tf.expand_dims(bbox_giou( pred_boxes3, real_boxes3), axis=-1)\n",
    "    bbox_loss_scale1 = 2.0 - 1.0 *  real_boxes1[:, :, :, :, 2:3] *  real_boxes1[:, :, :, :, 3:4] / (input_size * input_size )\n",
    "    bbox_loss_scale2 = 2.0 - 1.0 *  real_boxes2[:, :, :, :, 2:3] *  real_boxes2[:, :, :, :, 3:4] / (input_size * input_size )\n",
    "    bbox_loss_scale3 = 2.0 - 1.0 *  real_boxes3[:, :, :, :, 2:3] *  real_boxes3[:, :, :, :, 3:4] / (input_size * input_size )\n",
    "    giou_loss1 = bboxes1[:,:,:,:,4:5] * bbox_loss_scale1 * (1- giou1)\n",
    "    giou_loss2 = bboxes2[:,:,:,:,4:5] * bbox_loss_scale2 * (1- giou2)\n",
    "    giou_loss3 = bboxes3[:,:,:,:,4:5] * bbox_loss_scale3 * (1- giou3)\n",
    "    \n",
    "    #iou1 = bboxes1[:,:,:,:,4:5] * (1-tf.expand_dims(bbox_giou(pred_boxes1 , real_boxes1),axis=-1))\n",
    "    #iou2 = bboxes2[:,:,:,:,4:5] * (1-tf.expand_dims(bbox_giou(pred_boxes2 , real_boxes2),axis=-1))\n",
    "    #iou3 = bboxes3[:,:,:,:,4:5] * (1-tf.expand_dims(bbox_giou(pred_boxes3 , real_boxes3),axis=-1))\n",
    "\n",
    "    Iou_loss1 = tf.reduce_mean(tf.reduce_sum(giou_loss1,axis=[1,2,3,4]))\n",
    "    Iou_loss2 = tf.reduce_mean(tf.reduce_sum(giou_loss2,axis=[1,2,3,4]))\n",
    "    Iou_loss3 = tf.reduce_mean(tf.reduce_sum(giou_loss3,axis=[1,2,3,4]))\n",
    "    \n",
    "    Iou_loss = Iou_loss1 + Iou_loss2 + Iou_loss3\n",
    "    #损失3：图像损失\n",
    "    image_loss = tf.keras.losses.binary_crossentropy(image_label,output_data_image)\n",
    "    Image_loss = tf.reduce_mean(tf.reduce_sum(image_loss, axis=[1,2]))\n",
    "    \n",
    "    #损失4：confidecnce损失\n",
    "    \n",
    "    conv_raw_conf1 = conv_raw1[:,:,:,:,4:5]#没过sigmoid的\n",
    "    conv_raw_conf2 = conv_raw2[:,:,:,:,4:5]\n",
    "    conv_raw_conf3 = conv_raw3[:,:,:,:,4:5]\n",
    "    \n",
    "    pred_conf1 = outputbox1[:,:,:,:,4:5]\n",
    "    pred_conf2 = outputbox2[:,:,:,:,4:5]\n",
    "    pred_conf3 = outputbox3[:,:,:,:,4:5]\n",
    "    \n",
    "    IOU_LOSS_THRESH = 0.3\n",
    "    \n",
    "    max_iou1 = tf.expand_dims(tf.reduce_max(bbox_iou(pred_boxes1[:, :, :, :, np.newaxis, :], batch_lbboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]), axis=-1), axis=-1)\n",
    "    max_iou2 = tf.expand_dims(tf.reduce_max(bbox_iou(pred_boxes2[:, :, :, :, np.newaxis, :], batch_mbboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]), axis=-1), axis=-1)\n",
    "    max_iou3 = tf.expand_dims(tf.reduce_max(bbox_iou(pred_boxes3[:, :, :, :, np.newaxis, :], batch_sbboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]), axis=-1), axis=-1)\n",
    "    \n",
    "    respond_bgd1 = (1.0 - bboxes1[:,:,:,:,4:5]) * tf.cast( max_iou1 < IOU_LOSS_THRESH, tf.float32 )\n",
    "    respond_bgd2 = (1.0 - bboxes2[:,:,:,:,4:5]) * tf.cast( max_iou2 < IOU_LOSS_THRESH, tf.float32 )\n",
    "    respond_bgd3 = (1.0 - bboxes3[:,:,:,:,4:5]) * tf.cast( max_iou3 < IOU_LOSS_THRESH, tf.float32 )\n",
    "\n",
    "    conf_focal1 = tf.pow(bboxes1[:,:,:,:,4:5] - pred_conf1, 2)\n",
    "    conf_focal2 = tf.pow(bboxes2[:,:,:,:,4:5] - pred_conf2, 2)\n",
    "    conf_focal3 = tf.pow(bboxes3[:,:,:,:,4:5] - pred_conf3, 2)\n",
    "\n",
    "    conf_loss1 = conf_focal1 * (\n",
    "            bboxes1[:,:,:,:,4:5] * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes1[:,:,:,:,4:5], logits=conv_raw_conf1+1e-10)\n",
    "            +\n",
    "            respond_bgd1 * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes1[:,:,:,:,4:5], logits=conv_raw_conf1+1e-10)\n",
    "    )\n",
    "    \n",
    "    conf_loss2 = conf_focal2 * (\n",
    "            bboxes2[:,:,:,:,4:5] * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes2[:,:,:,:,4:5], logits=conv_raw_conf2+1e-10)\n",
    "            +\n",
    "            respond_bgd2 * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes2[:,:,:,:,4:5], logits=conv_raw_conf2+1e-10)\n",
    "    )\n",
    "    \n",
    "    conf_loss3 = conf_focal3 * (\n",
    "            bboxes3[:,:,:,:,4:5] * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes3[:,:,:,:,4:5], logits=conv_raw_conf3+1e-10)\n",
    "            +\n",
    "            respond_bgd3 * tf.nn.sigmoid_cross_entropy_with_logits(labels=bboxes3[:,:,:,:,4:5], logits=conv_raw_conf3+1e-10)\n",
    "    )\n",
    "\n",
    "    Conf_loss1 = tf.reduce_mean(tf.reduce_sum(conf_loss1,axis=[1,2,3]))\n",
    "    Conf_loss2 = tf.reduce_mean(tf.reduce_sum(conf_loss2,axis=[1,2,3]))\n",
    "    Conf_loss3 = tf.reduce_mean(tf.reduce_sum(conf_loss3,axis=[1,2,3]))\n",
    "    \n",
    "    Conf_loss  = Conf_loss1+Conf_loss2+Conf_loss3\n",
    "\n",
    "    return Image_loss, Prob_loss, Iou_loss, Conf_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2561b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据集\n",
    "image_dir= r'F:\\HCJ_for_AI_training\\YOLO-crack\\Image'\n",
    "#label的分类\n",
    "LABEL_BOX=['zong','wang','xie','heng']\n",
    "\n",
    "LABEL_number=[0,1,2,3]\n",
    "\n",
    "def get_image_and_labels_paths(image_dir:str):\n",
    "    '''\n",
    "    获取所有图片与对应标签的路径 \n",
    "    '''\n",
    "    label_dir = r'F:\\HCJ_for_AI_training\\YOLO-crack\\Labels'\n",
    "    all_paths=[]\n",
    "    all_label_data_path = []\n",
    "    all_image_S_path = []\n",
    "    image_original_path = pathlib.Path(image_dir)\n",
    "    all_image_o_path = list(image_original_path.glob('*/*'))\n",
    "    all_image_o_path = [str(p) for p in  all_image_o_path]\n",
    "    for p in all_image_o_path:\n",
    "        all_label_data_path.append(label_dir +'\\\\'+ p[-10:-4] + '.txt')\n",
    "        all_image_S_path.append(label_dir +'\\\\'+ p[-10:-4] + '.png')\n",
    "    for i in range(len(all_image_o_path)):\n",
    "        all_paths.append([all_image_o_path[i], all_label_data_path[i],all_image_S_path[i]])\n",
    "    random.shuffle(all_paths)\n",
    "    return all_paths\n",
    "\n",
    "paths = get_image_and_labels_paths(image_dir) \n",
    "#paths_count = len(paths)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "#创建图片路径及其数字标签的dataset\n",
    "My_dataset = tf.data.Dataset.from_tensor_slices(paths)\n",
    "My_dataset  = My_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "def load_image(image_path):\n",
    "    image_path = (str(image_path)[12:-26]).replace(\"\\\\\\\\\",\"/\")\n",
    "    image = cv2.imread(image_path)\n",
    "    return image\n",
    "\n",
    "def load_label(label_path):\n",
    "    label_path = (str(label_path)[12:-26]).replace(\"\\\\\\\\\",\"/\")\n",
    "    label = open(label_path)\n",
    "    result=[]\n",
    "    for line in label.readlines():\n",
    "        line = line.strip('\\n')  #去掉列表中每一个元素的换行符\n",
    "        Line = line.split() \n",
    "        result.append(Line)\n",
    "    result = np.array(result,dtype = float)\n",
    "    #print(result)\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        result[i][0]=result[i][0]-15\n",
    "  \n",
    "    return result\n",
    "\n",
    "def load_image_label(image_label_path):\n",
    "    image_path = (str(image_label_path)[12:-26]).replace(\"\\\\\\\\\",\"/\")\n",
    "    image = cv2.imread(image_path,0)\n",
    "    image = image[...,np.newaxis]\n",
    "    return image\n",
    "\n",
    "def image_preporcess(image, target_size,  image_label, gt_boxes=None,):\n",
    "    #图和target统一进行640的resize\n",
    "    #boxes:(x,y,w,h)的百分比\n",
    "    ih, iw    = target_size\n",
    "    h,  w, _  = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "    #print(np.array(image_label).shape)\n",
    "    image_label_resized = cv2.resize(image_label, (nw, nh))[:,:, np.newaxis]\n",
    "    #print(np.array(image_label_resized).shape)\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=0)\n",
    "    image_label_paded = np.full(shape=[ih, iw, 1], fill_value=0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    \n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    image_label_paded[dh:nh+dh, dw:nw+dw,:] = image_label_resized\n",
    "    image_label_paded = image_label_paded / 255.\n",
    "    \n",
    "    if gt_boxes is None:\n",
    "        return image_paded,image_label_paded\n",
    "\n",
    "    else:\n",
    "        gt_boxescopy = copy.deepcopy(gt_boxes)\n",
    "        #(px,py,pw,ph) →(x,y,w,h)       \n",
    "        gt_boxescopy[:, [1, 3]] = gt_boxescopy[:, [1, 3]] * w * scale + dw \n",
    "        gt_boxescopy[:, [2, 4]] = gt_boxescopy[:, [2, 4]] * h * scale + dh\n",
    "        \n",
    "        gt_boxescopy_R = gt_boxescopy\n",
    "\n",
    "    return image_paded, gt_boxescopy_R, image_label_paded\n",
    "\n",
    "def preprocess_true_boxes(bboxes, anchors):\n",
    "    with tf.device('/cpu:0'):\n",
    "        num_classes=4\n",
    "        anchor_per_scale = 3\n",
    "        max_bbox_per_scale = 10\n",
    "        batch_count = 0\n",
    "        train_input_size = random.choice([640])\n",
    "        train_output_sizes = train_input_size // np.array([8,16,32])\n",
    "        strides = np.array([8,16,32])\n",
    "        \n",
    "        label = [np.zeros((train_output_sizes[i], train_output_sizes[i], anchor_per_scale,\n",
    "                           5 + num_classes)) for i in range(3)]\n",
    "        bboxes_xywh = [np.zeros((max_bbox_per_scale, 4)) for _ in range(3)]\n",
    "        bbox_count = np.zeros((3,))\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            bbox_coor = bbox[1:]\n",
    "            bbox_class_ind = int(bbox[0])\n",
    "\n",
    "            onehot = np.zeros(num_classes, dtype=np.float)\n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "            uniform_distribution = np.full(num_classes, 1.0 / num_classes)\n",
    "            deta = 0.01\n",
    "            smooth_onehot = onehot * (1 - deta) + deta * uniform_distribution\n",
    "\n",
    "            #bbox_xywh = np.concatenate([(bbox_coor[2:] + bbox_coor[:2]) * 0.5, bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "            bbox_xywh =  bbox_coor\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / strides[:, np.newaxis]\n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False\n",
    "            for i in range(3):\n",
    "                anchors_xywh = np.zeros((anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32) + 0.5\n",
    "                anchors_xywh[:, 2:4] = anchors[i]\n",
    "\n",
    "                iou_scale = bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)\n",
    "                #print(iou_scale)\n",
    "                iou.append(iou_scale)\n",
    "                iou_mask = iou_scale > 0.3\n",
    "\n",
    "                if np.any(iou_mask):\n",
    "                    xind, yind = np.floor(bbox_xywh_scaled[i, 0:2]).astype(np.int32)\n",
    "\n",
    "                    label[i][yind, xind, iou_mask, :] = 0\n",
    "                    label[i][yind, xind, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yind, xind, iou_mask, 4:5] = 1.0\n",
    "                    label[i][yind, xind, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    bbox_ind = int(bbox_count[i] % max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1\n",
    "\n",
    "                    exist_positive = True\n",
    "\n",
    "            if not exist_positive:\n",
    "                best_anchor_ind = np.argmax(np.array(iou).reshape(-1), axis=-1)\n",
    "                best_detect = int(best_anchor_ind / anchor_per_scale)\n",
    "                best_anchor = int(best_anchor_ind % anchor_per_scale)\n",
    "                xind, yind = np.floor(bbox_xywh_scaled[best_detect, 0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yind, xind, best_anchor, :] = 0\n",
    "                label[best_detect][yind, xind, best_anchor, 0:4] = bbox_xywh\n",
    "                label[best_detect][yind, xind, best_anchor, 4:5] = 1.0\n",
    "                label[best_detect][yind, xind, best_anchor, 5:] = smooth_onehot\n",
    "                \n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh\n",
    "                bbox_count[best_detect] += 1\n",
    "\n",
    "        label_lbbox, label_mbbox, label_sbbox = label\n",
    "        lbboxes, mbboxes, sbboxes = bboxes_xywh\n",
    "        return label_lbbox, label_mbbox, label_sbbox, lbboxes, mbboxes, sbboxes\n",
    "    \n",
    "def get_train_data(image_batch, gt_boxes_batch,image_label_batch, anchors):\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        num_classes=4\n",
    "        anchor_per_scale = 3\n",
    "        max_bbox_per_scale = 10\n",
    "        batch_size=len(image_batch)\n",
    "        \n",
    "        Image_label = np.zeros((batch_size, 640,640, 2),dtype=np.float32)\n",
    "        \n",
    "        train_input_size = random.choice([640])\n",
    "        train_output_sizes = train_input_size // np.array([8,16,32])\n",
    "\n",
    "        batch_image = np.zeros((batch_size, train_input_size, train_input_size, 3), dtype=np.float32)\n",
    "\n",
    "        batch_label_1bbox = np.zeros((batch_size, train_output_sizes[0], train_output_sizes[0],\n",
    "                                      anchor_per_scale, 5 + num_classes), dtype=np.float32)\n",
    "        batch_label_2bbox = np.zeros((batch_size, train_output_sizes[1], train_output_sizes[1],\n",
    "                                      anchor_per_scale, 5 + num_classes), dtype=np.float32)\n",
    "        batch_label_3bbox = np.zeros((batch_size, train_output_sizes[2], train_output_sizes[2],\n",
    "                                      anchor_per_scale, 5 + num_classes), dtype=np.float32)\n",
    "\n",
    "        batch_lbboxes = np.zeros((batch_size, max_bbox_per_scale, 4), dtype=np.float32)\n",
    "        batch_mbboxes = np.zeros((batch_size, max_bbox_per_scale, 4), dtype=np.float32)\n",
    "        batch_sbboxes = np.zeros((batch_size, max_bbox_per_scale, 4), dtype=np.float32)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "\n",
    "            image, bboxes, image_label = image_preporcess(image_batch[i], (train_input_size,train_input_size),image_label_batch[i], gt_boxes=gt_boxes_batch[i])\n",
    "\n",
    "            Image_label[i,:,:,:]=tf.one_hot(image_label[:,:,0],depth=2)\n",
    "\n",
    "            label_lbbox, label_mbbox, label_sbbox, lbboxes, mbboxes, sbboxes = preprocess_true_boxes(bboxes,anchors)\n",
    "\n",
    "            batch_image[i, :, :, :] = image\n",
    "            batch_label_1bbox[i, :, :, :, :] = label_lbbox\n",
    "            batch_label_2bbox[i, :, :, :, :] = label_mbbox\n",
    "            batch_label_3bbox[i, :, :, :, :] = label_sbbox\n",
    "            batch_lbboxes[i, :, :] = lbboxes\n",
    "            batch_mbboxes[i, :, :] = mbboxes\n",
    "            batch_sbboxes[i, :, :] = sbboxes\n",
    "        \n",
    "        return batch_image, Image_label, batch_label_1bbox, batch_label_2bbox,batch_label_3bbox,  batch_lbboxes,batch_mbboxes,batch_sbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c939e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_boxes(pred_bbox, org_img_shape, input_size, score_threshold):\n",
    "\n",
    "    valid_scale=[0, np.inf] \n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # # (1) (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
    "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "    # # (2) (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
    "    org_h, org_w = org_img_shape\n",
    "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2\n",
    "    dh = (input_size - resize_ratio * org_h) / 2\n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # # (3) clip some boxes those are out of range\n",
    "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
    "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0\n",
    "\n",
    "    # # (4) discard some invalid boxes\n",
    "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
    "    \n",
    "    # # (5) discard some boxes with low scores\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "    \n",
    "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    \"\"\"\n",
    "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
    "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
    "          https://github.com/bharatsingh430/soft-nms\n",
    "    \"\"\"\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "\n",
    "        while len(cls_bboxes) > 0:\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0\n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0.\n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area    = boxes1_area + boxes2_area - inter_area\n",
    "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "########训练#########\n",
    "trainset = My_dataset\n",
    "logdir = \"./data/log\"\n",
    "NUM_CLASS  = 4\n",
    "\"\"\"\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = 2 * steps_per_epoch\n",
    "total_steps = 30 * steps_per_epoch\n",
    "lr = TRAIN_LR_INIT = 1e-3\n",
    "TRAIN_LR_END = 1e-6\n",
    "\"\"\"\n",
    "lr = TRAIN_LR_INIT = 1e-4\n",
    "YOLOv5,anchors=run()\n",
    "#print(anchors)\n",
    "#YOLOv5.summary()\n",
    "#YOLOv5.load_weights(\"./yolov5-裂缝\")\n",
    "optimizer = tf.keras.optimizers.Adam(TRAIN_LR_INIT)\n",
    "\n",
    "#count=0\n",
    "History=[]\n",
    "for epoch in range(0,400,1):\n",
    "    count=0\n",
    "    My_dataset = My_dataset.shuffle(1000)\n",
    "    for batch_size in My_dataset:\n",
    "        count+=1\n",
    "        train_image = []\n",
    "        train_label = [] \n",
    "        train_image_S = []\n",
    "        for i in range(len(batch_size)):\n",
    "            train_image.append(load_image(batch_size[i][0]))\n",
    "            train_label.append(load_label(batch_size[i][1]))\n",
    "            #print(batch_size[i][1])\n",
    "            train_image_S.append(load_image_label(batch_size[i][2]))\n",
    "            \n",
    "            #print(np.array(train_image_S[i].shape))\n",
    "            #print(np.array(train_image[i].shape))\n",
    "            #print(batch_size[i][2])\n",
    "\n",
    "        image_data, image_label ,batch_boxes_1,batch_boxes_2,batch_boxes_3,batch_lbboxes,batch_mbboxes,batch_sbboxes = get_train_data(train_image, train_label, train_image_S,anchors)\n",
    "\n",
    "        image_data=np.array(image_data)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            output_image, output = YOLOv5(image_data)\n",
    "            \n",
    "            decode_output1,decode_output2,decode_output3 = decode(output[0], output[1], output[2],anchors)\n",
    "            #decode_output1,decode_output2,decode_output3 = output[0],output[1],output[2]\n",
    "            \n",
    "            Image_loss=Prob_loss=Giou_loss=Conf_loss=0\n",
    "\n",
    "            # optimizing process\n",
    "\n",
    "            Image_loss, Prob_loss, Iou_loss, Conf_loss = compute_loss(output_image, decode_output1,decode_output2,decode_output3,\n",
    "                                                          batch_boxes_1,batch_boxes_2,batch_boxes_3,\n",
    "                                                          image_label,\n",
    "                                                          batch_lbboxes,batch_mbboxes,batch_sbboxes,\n",
    "                                                          output[0],output[1],output[2])\n",
    "            \n",
    "            total_loss =   Image_loss + Prob_loss +  Iou_loss +  Conf_loss\n",
    "            gradients = tape.gradient(total_loss, YOLOv5.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients,YOLOv5.trainable_variables))\n",
    "            tf.print(\"=>Epoch%4d STEP %4d Prob_loss:%4.2f Iou_loss: %4.2f Conf_loss:%4.2f total_loss:%4.2f\" \n",
    "                     %(epoch, count,Prob_loss, Iou_loss, Conf_loss,total_loss))     \n",
    "            \n",
    "            #学习率更新\n",
    "            \n",
    "            global_steps.assign_add(1)\n",
    "            if global_steps < warmup_steps:\n",
    "                lr = global_steps / warmup_steps *TRAIN_LR_INIT\n",
    "            else:\n",
    "                lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END) * (\n",
    "                    (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi))\n",
    "                )\n",
    "            optimizer.lr.assign(lr.numpy())\n",
    "            \n",
    "            History.append([epoch, optimizer.lr.numpy(),Prob_loss, Iou_loss, Conf_loss,total_loss,mAP])\n",
    "    \n",
    "        YOLOv5.save_weights(\"./YOLO-Crack\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
